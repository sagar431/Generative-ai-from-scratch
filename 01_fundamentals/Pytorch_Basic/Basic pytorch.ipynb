{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3c517-2e90-481d-8fbd-9bbd1f358418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae1280f5-cff1-4c2b-b58e-8e6bbbb7c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data handling\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Utility libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c7388-2056-462f-a1a0-036009447d13",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6408a2-fe54-49cd-876c-6462b78d52c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tensor is a spcialized multi-dimesinal array for mathematical and computaional efficiency\n",
    "# 5D Tesnor video data \n",
    "\n",
    "#why are tensor useful ?\n",
    "#1.Mathematical operations\n",
    "#2.Efficeint Computation \n",
    "#3.Efficient Computation\n",
    "\n",
    "\n",
    "#where are tensor used in Deep learning ?\n",
    "\n",
    "#1 Data storage \n",
    "#2 Weight and Biases\n",
    "#3 Matrix oepration \n",
    "\n",
    "# 4 Training process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f68e2f-e16e-4d37-8cb2-036b965d1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "286524cf-856f-4b1e-b72e-bcbbe667087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch MPS backend is available and built!\n",
      "Using device: mps\n",
      "Successfully created a tensor on the MPS device:\n",
      "tensor([1., 1., 1., 1., 1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    # Check if PyTorch was built with MPS support\n",
    "    if torch.backends.mps.is_built():\n",
    "        print(\"PyTorch MPS backend is available and built!\")\n",
    "        # Set the device\n",
    "        mps_device = torch.device(\"mps\")\n",
    "        print(f\"Using device: {mps_device}\")\n",
    "\n",
    "        # Example: Create a tensor on the MPS device\n",
    "        try:\n",
    "            x = torch.ones(5, device=mps_device)\n",
    "            print(\"Successfully created a tensor on the MPS device:\")\n",
    "            print(x)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create tensor on MPS device: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"MPS not available because the current PyTorch install was not built with MPS enabled.\")\n",
    "\n",
    "else:\n",
    "    # This might mean the macOS version is too old (needs 12.3+)\n",
    "    # or the hardware doesn't support MPS.\n",
    "    print(\"MPS not available. Check your macOS version (12.3+ needed) and hardware.\")\n",
    "    print(\"Falling back to CPU.\")\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {cpu_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb44a4-3dbf-4940-8540-d93d85d2d001",
   "metadata": {},
   "source": [
    "## Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3f134f2-b3f8-4afc-9dc9-082b838cd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using empty \n",
    "a=torch.empty(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28f6b357-b714-447e-95a2-c9dde02d81e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check type\n",
    "type(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab776e3-3937-4ed1-bc89-34e08b579c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7771c391-5245-477b-8b71-1a2017d1f42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e499c42-4df1-4d9a-97da-9a4c52b9b07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7534, 0.1258, 0.5249],\n",
       "        [0.6063, 0.7897, 0.8261],\n",
       "        [0.7403, 0.0518, 0.5476]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ace1cd6-a14f-4501-8e21-670c98f581ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1117, 0.8158, 0.2626],\n",
       "        [0.4839, 0.6765, 0.7539],\n",
       "        [0.2627, 0.0428, 0.2080]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "torch.rand(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cce6c-7728-44b4-8e1f-100a094f6eda",
   "metadata": {},
   "source": [
    "## Tensor Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dcbc302-53a5-48de-8886-4ac7a2c4a022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([[1,2,3],[4,5,6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ac28fe9-c4e9-4d5e-afe3-2c0850e0e45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ca3d1f-72d5-422b-9d61-eced7beede72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cf1b615-7e33-452c-bfac-7405aaf9c941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1180, 0.1217, 0.7356],\n",
       "        [0.7118, 0.7876, 0.4183]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(x,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e8b60-5f91-4b69-9b01-91d8b055eb16",
   "metadata": {},
   "source": [
    "## Tensor Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0399746c-3a98-4737-8f08-bd1d78adba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0000df6-7dd6-4ebd-92b2-213623b80041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assing data type\n",
    "torch.tensor([1.0,2.0,3.0],dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d718fb-232c-437d-ab76-a4e189125f41",
   "metadata": {},
   "source": [
    "### matehmatical operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f17caf3f-b9ab-4369-9036-c592090c14bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e476b84-af01-42a1-983c-bde3ee8503dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  0,  1],\n",
       "        [ 2,  3,  4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f1eabf9-ca55-42f0-b83a-24eff0a33fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6,  9],\n",
       "        [12, 15, 18]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eccb9830-7e7d-4c0a-89fd-405df0925710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.6667, 1.0000],\n",
       "        [1.3333, 1.6667, 2.0000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ae810c0-6333-4577-98e7-708c7896a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [16, 25, 36]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60ca51e7-9717-4ea5-b77a-ace8d09a6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elment wise operations\n",
    "\n",
    "a=torch.rand(2,3)\n",
    "b=torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be0afd7f-1caa-48f3-8dc5-c9a3e009db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9014, 0.9969, 0.7565],\n",
      "        [0.2239, 0.3023, 0.1784]])\n",
      "tensor([[0.8238, 0.5557, 0.9770],\n",
      "        [0.4440, 0.9478, 0.7445]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42c9b1c5-9990-42c8-954a-1cb42aca3482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7253, 1.5526, 1.7335],\n",
       "        [0.6679, 1.2502, 0.9229]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c8ba614-5301-41c3-a499-ddbb11a71450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0776,  0.4411, -0.2205],\n",
       "        [-0.2201, -0.6455, -0.5661]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72cf5e4b-17b3-4707-9f01-91fe7e771288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7426, 0.5540, 0.7391],\n",
       "        [0.0994, 0.2866, 0.1328]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b33f493-0ac7-415b-8758-92751ec0ea4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9180, 0.9983, 0.7614],\n",
       "        [0.5145, 0.3218, 0.2771]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a**b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5482418-26b0-4f96-b208-bf6d888fa06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0942, 1.7938, 0.7743],\n",
       "        [0.5042, 0.3190, 0.2397]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028824db-6b8b-4aa2-855f-364fcf5cf253",
   "metadata": {},
   "source": [
    "## Reduction operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5895e413-d371-4aed-898c-c1418b464e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 5., 7.],\n",
       "        [3., 9., 4.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=torch.randint(size=(2,3),low=0,high=10,dtype=torch.float32)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb848467-8147-4de3-b3ed-5f79c30c2802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(37.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11bf2bbd-4aee-4ab5-bf0b-7260f143f713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14., 11.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(e,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52e04fae-3bc1-49a7-a078-23dfa0b9f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.1667)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f72161b-21ae-4d24-b197-e569ee7e67e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34020.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.prod(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dfe5e2-125f-48ec-8b23-3b1f8bc05328",
   "metadata": {},
   "source": [
    "## Matrix oepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db55f608-5504-4860-9c42-880e666d92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=torch.randint(size=(2,3),low=0,high=10)\n",
    "g=torch.randint(size=(3,2),low=0,high=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42c8d78c-0685-4d54-bc54-796fc40f82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 5, 7],\n",
      "        [5, 9, 9]])\n",
      "tensor([[7, 5],\n",
      "        [9, 8],\n",
      "        [9, 7]])\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93d6ecfb-99b5-43a1-85f1-e0458f2749e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[108,  89],\n",
       "        [197, 160]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix multi\n",
    "torch.matmul(f,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3978ac8a-1602-4d26-9dd8-5d6c28e1efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=torch.randint(size=(3,3),low=0,high=10,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f36de-2884-4c20-b8bf-cbccdacd5d50",
   "metadata": {},
   "source": [
    "## inpalce operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c57efdc7-f9f1-4ae6-b31c-b7e8ffa502dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=torch.rand(2,3)\n",
    "n=torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b0e4a87-a93b-46af-a2ad-9494262b0be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3039, 0.6726, 0.5740],\n",
      "        [0.9233, 0.9178, 0.7590]])\n",
      "tensor([[0.7775, 0.6179, 0.3379],\n",
      "        [0.2170, 0.9454, 0.7116]])\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf6101ea-acec-4884-afc3-1f6a496103dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0814, 1.2905, 0.9118],\n",
       "        [1.1403, 1.8632, 1.4706]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.add_(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9d9c58c-1612-4109-b60f-c3553d34e8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0814, 1.2905, 0.9118],\n",
       "        [1.1403, 1.8632, 1.4706]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29027aba-ac39-426f-a6f5-89779f2d0e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7775, 0.6179, 0.3379],\n",
       "        [0.2170, 0.9454, 0.7116]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b1c72-deab-40af-9e31-a0c46eccadd7",
   "metadata": {},
   "source": [
    "## Copying a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a95974c-4907-4d22-9cbe-5f532da0bdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b748b51-b95f-47d1-ad41-f06878d39f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a02ce719-aa16-4fed-9685-915cbe741658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1157, 0.6574, 0.3451],\n",
       "        [0.0453, 0.9798, 0.5548]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "395c4fde-5555-4644-9422-59d0e8e3f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "424f3d71-6084-4ed3-b45f-d2684277282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6574, 0.3451],\n",
       "        [0.0453, 0.9798, 0.5548]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57d492a5-130b-43a3-8776-99f1f1cc8d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6574, 0.3451],\n",
       "        [0.0453, 0.9798, 0.5548]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e36c0f4-5974-414e-97f0-237067da2c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13072522640"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a205accc-f147-40e5-8b3c-7ac54141ebc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13072522640"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b4a6485-85da-438b-b817-126e2fc2ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3ef0f85-1384-4584-b777-806bcec9ebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6574, 0.3451],\n",
       "        [0.0453, 0.9798, 0.5548]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69dad211-ff55-4113-8483-607c60ad4cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6574, 0.3451],\n",
       "        [0.0453, 0.9798, 0.5548]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7323cda7-c7cd-48d3-ad27-8ed65d8bb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9cbab26f-3472-41a5-a391-17f4706d5811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000,  0.6574,  0.3451],\n",
       "        [ 0.0453,  0.9798,  0.5548]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c0daca7-b278-468d-a44c-ac972dbbf2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.6574, 0.3451],\n",
       "        [0.0453, 0.9798, 0.5548]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b6488-cea2-430f-aeff-e0fe2eee7085",
   "metadata": {},
   "source": [
    "## Tesnor operation on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3dcaa0c5-ee53-4d0a-a67b-234a1cbcc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe34faac-779f-4b57-8c83-52a87e183ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4643, 0.8532, 0.4872],\n",
       "        [0.4602, 0.4261, 0.0968]], device='mps:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new tensor on gpu\n",
    "\n",
    "torch.rand((2,3),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15894488-2d39-40d5-87ea-e9cec264b911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000,  0.6574,  0.3451],\n",
       "        [ 0.0453,  0.9798,  0.5548]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving an existinf tenosr to gpu \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58410cef-b788-4436-beaf-5f22838acf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000,  0.6574,  0.3451],\n",
       "        [ 0.0453,  0.9798,  0.5548]], device='mps:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a730fec3-866b-4eb6-b3c7-9668256997f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 5.6574, 5.3451],\n",
       "        [5.0453, 5.9798, 5.5548]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7a69538-3d26-474f-b65e-7598ab3889b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.0000,  5.6574,  5.3451],\n",
       "        [ 5.0453,  5.9798,  5.5548]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14152133-a477-42a0-aef7-15ba912cb48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Matrix Multiplication Benchmark...\n",
      "PyTorch Version: 2.5.1\n",
      "Platform: Darwin 24.4.0 (arm64)\n",
      "\n",
      "--- Benchmarking on CPU ---\n",
      "Matrix Size: 4096x4096\n",
      "Iterations: 50\n",
      "Data Type: torch.float32\n",
      "Total time for 50 iterations: 4.4706 seconds\n",
      "Average time per multiplication: 89.4111 milliseconds\n",
      "\n",
      "--- Benchmarking on MPS ---\n",
      "Matrix Size: 4096x4096\n",
      "Iterations: 50\n",
      "Data Type: torch.float32\n",
      "Total time for 50 iterations: 2.0341 seconds\n",
      "Average time per multiplication: 40.6817 milliseconds\n",
      "\n",
      "--- Results Summary ---\n",
      "CPU Average Time: 89.4111 ms\n",
      "MPS Average Time: 40.6817 ms\n",
      "\n",
      "GPU (MPS) is approximately 2.20 times faster than CPU for this task.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import platform\n",
    "\n",
    "def benchmark_matmul(device_name, matrix_size, iterations):\n",
    "    \"\"\"\n",
    "    Benchmarks matrix multiplication on a specified device.\n",
    "\n",
    "    Args:\n",
    "        device_name (str): 'cpu' or 'mps'.\n",
    "        matrix_size (int): Dimension of the square matrices (e.g., 4096).\n",
    "        iterations (int): Number of times to repeat the multiplication.\n",
    "\n",
    "    Returns:\n",
    "        float: Average time per matrix multiplication in milliseconds.\n",
    "               Returns None if the device is 'mps' but not available.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Benchmarking on {device_name.upper()} ---\")\n",
    "    \n",
    "    # Check if MPS device is requested and available\n",
    "    if device_name == \"mps\":\n",
    "        if not torch.backends.mps.is_available():\n",
    "            print(\"MPS device not found or not supported on this system/PyTorch build.\")\n",
    "            print(\"Skipping MPS benchmark.\")\n",
    "            return None\n",
    "        if not torch.backends.mps.is_built():\n",
    "             print(\"Current PyTorch install was not built with MPS enabled.\")\n",
    "             print(\"Skipping MPS benchmark.\")\n",
    "             return None\n",
    "        # Additional check for macOS version compatibility might be useful\n",
    "        # though is_available() generally covers it.\n",
    "\n",
    "    try:\n",
    "        # Set the device\n",
    "        device = torch.device(device_name)\n",
    "\n",
    "        # Create random matrices directly on the target device\n",
    "        # Using float32 as it's commonly used and well-supported\n",
    "        a = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)\n",
    "        b = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)\n",
    "\n",
    "        print(f\"Matrix Size: {matrix_size}x{matrix_size}\")\n",
    "        print(f\"Iterations: {iterations}\")\n",
    "        print(f\"Data Type: {a.dtype}\")\n",
    "\n",
    "        # Warm-up: Perform one multiplication before timing\n",
    "        # This helps account for initialization overhead (especially on GPU)\n",
    "        _ = torch.matmul(a, b)\n",
    "\n",
    "        # --- Synchronization is crucial for accurate GPU timing ---\n",
    "        if device.type == 'mps':\n",
    "            # Wait for the warm-up operation to complete on the GPU\n",
    "            torch.mps.synchronize()\n",
    "\n",
    "        # Start timer\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Perform the multiplication multiple times\n",
    "        for _ in range(iterations):\n",
    "            _ = torch.matmul(a, b)\n",
    "\n",
    "        # --- Synchronization before stopping timer ---\n",
    "        if device.type == 'mps':\n",
    "            # Wait for all queued GPU operations to finish\n",
    "            torch.mps.synchronize()\n",
    "\n",
    "        # Stop timer\n",
    "        end_time = time.perf_counter()\n",
    "\n",
    "        # Calculate times\n",
    "        total_time = end_time - start_time\n",
    "        avg_time_sec = total_time / iterations\n",
    "        avg_time_ms = avg_time_sec * 1000\n",
    "\n",
    "        print(f\"Total time for {iterations} iterations: {total_time:.4f} seconds\")\n",
    "        print(f\"Average time per multiplication: {avg_time_ms:.4f} milliseconds\")\n",
    "\n",
    "        # Clean up memory (optional, but good practice)\n",
    "        del a, b\n",
    "        if device.type == 'mps':\n",
    "            torch.mps.empty_cache()\n",
    "\n",
    "        return avg_time_ms\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the {device_name.upper()} benchmark: {e}\")\n",
    "        # If it's an MPS memory error, suggest smaller size\n",
    "        if device_name == 'mps' and isinstance(e, RuntimeError) and 'allocated' in str(e).lower():\n",
    "             print(\"This might be an Out-of-Memory error on the GPU. Try a smaller 'matrix_size'.\")\n",
    "        return None\n",
    "\n",
    "# --- Configuration ---\n",
    "matrix_size = 4096  # Dimension of the square matrix (e.g., 1024, 2048, 4096)\n",
    "                    # Adjust based on your system's RAM/VRAM. Start smaller if unsure.\n",
    "iterations = 50     # Number of multiplications to average over (more iterations give smoother results)\n",
    "\n",
    "# --- Run Benchmarks ---\n",
    "print(\"Starting Matrix Multiplication Benchmark...\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Platform: {platform.system()} {platform.release()} ({platform.machine()})\")\n",
    "\n",
    "\n",
    "# Benchmark CPU\n",
    "cpu_avg_time = benchmark_matmul('cpu', matrix_size, iterations)\n",
    "\n",
    "# Benchmark MPS (Apple Silicon GPU)\n",
    "mps_avg_time = benchmark_matmul('mps', matrix_size, iterations)\n",
    "\n",
    "# --- Comparison ---\n",
    "print(\"\\n--- Results Summary ---\")\n",
    "if cpu_avg_time is not None:\n",
    "    print(f\"CPU Average Time: {cpu_avg_time:.4f} ms\")\n",
    "if mps_avg_time is not None:\n",
    "    print(f\"MPS Average Time: {mps_avg_time:.4f} ms\")\n",
    "\n",
    "if cpu_avg_time is not None and mps_avg_time is not None:\n",
    "    speedup = cpu_avg_time / mps_avg_time\n",
    "    print(f\"\\nGPU (MPS) is approximately {speedup:.2f} times faster than CPU for this task.\")\n",
    "elif mps_avg_time is None and cpu_avg_time is not None:\n",
    "    print(\"\\nCould not perform MPS benchmark.\")\n",
    "else:\n",
    "    print(\"\\nCould not perform benchmarks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d078e4b-f8c3-488d-a04f-2c0f6777070d",
   "metadata": {},
   "source": [
    "## Reshaping tesnors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15ad61eb-51fe-498e-901c-31b19a19a4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.ones(4,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "301ba517-c923-4d34-a116-67a31733b3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1.],\n",
       "          [1., 1.]],\n",
       "\n",
       "         [[1., 1.],\n",
       "          [1., 1.]]],\n",
       "\n",
       "\n",
       "        [[[1., 1.],\n",
       "          [1., 1.]],\n",
       "\n",
       "         [[1., 1.],\n",
       "          [1., 1.]]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(2,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7217411c-f0d2-4c2b-ba21-753a89c36525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03f57c8a-2254-4316-bd94-654d2a8bc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.rand(226,226,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "050ea38e-7991-4efa-837b-bbbcc45a4995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 226, 226, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf60e9e-80ca-4c37-9d2d-131908c4602d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
