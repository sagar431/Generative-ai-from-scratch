{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "363f7198-c684-4791-8466-d92f1d99fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data handling\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Utility libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ddd26f-02fd-459a-b619-c7306de6b8a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def  dy_dx(x):\n",
    "    return 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6750cd-a441-48da-8742-a0d5ea3a673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_dx(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa3d49-ee7a-415e-910f-384a8e546d92",
   "metadata": {},
   "source": [
    "## Autograd is a core component of pytroch that provies automatic diffrentation for tensor operations .it enables gradient compuatation , which is  essentail for traning machine learning models using optmisation algo  like gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1830152-87ae-4e17-80e7-37293c6c9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95cfad98-0e15-4fbb-8895-109d3caa5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(3.0,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85094f0-091e-470c-95e9-8ca9026291ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7409ef-9130-4452-bb6b-8ea7211aea9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89cfeac-2378-495e-8483-3b79a57b043f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58306a5e-9497-46f8-82c1-8f8e15c8a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53797ddb-ad2e-44d5-92ec-25713b148391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab9e87c9-25da-4db9-9277-5e6ff791b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dz_dx(x):\n",
    "    return 2*x*math.cos(x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150e6236-afa9-4bb3-9965-0db1adb58c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.466781571308061"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dx(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870592f5-e97a-4ee7-a4e3-c026a90a7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(3.0,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ae89953-3582-4830-b814-76d135195250",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3205d9db-12f4-4ff8-8332-1b3beaeb5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a6b2905-031b-42fe-a43f-ebf438b7fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59489816-f428-4d55-92a4-c1a184330713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e84cfa8-4754-4059-a801-439f71ebc981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4121, grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b66cfe7-9273-4950-8b0b-36118feb1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89998fe6-2ff6-4c7c-9e2b-9f78e2cac242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5c12da3-6dbf-4d1b-a288-75d13ce21a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(6.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beaf2885-23ad-4c01-ae24-0e4d43b68cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cf87169-9318-46f1-96ec-8d8d1730e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.tensor(1.0,requires_grad=True)\n",
    "b=torch.tensor(0.0,requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45a4f64e-13f1-49b1-bc66-4212c2018246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a8d0772-0d8d-4847-9b73-fb6003efeb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9a9e6b0-c3d1-4d42-9c15-76570e2d0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a2014e7-1be5-4f2d-beeb-ce30e546afac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d0a5627-1ee9-4f53-ae43-6805328f1334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=torch.sigmoid(z)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1ef4e87-a7ee-4dfa-a850-e3e5e55d636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "loss=bce_loss(y_pred,y)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3daa5f3-41a9-4cd6-9891-c09ee772c3e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b8900ba-166b-424c-932b-18dc1872f368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6918)\n",
      "tensor(0.9988)\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae0dee-6f15-4941-baaa-6fac456db83f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#when preidction time there is no need of backword pass \n",
    "\n",
    "#option 1 -require_grad_(False)\n",
    "#option 2-detach()\n",
    "#ption 3 -torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccaf49b4-93e0-4d9c-a67b-0b3e21d212cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Tensors ---\n",
      "Tensor x: 2.0\n",
      "Tensor y: 3.0\n",
      "--------------------\n",
      "--- Performing Operations ---\n",
      "Tensor z = x * y + x^2: 10.0\n",
      "Gradient function for z: <AddBackward0 object at 0x306abbe50>\n",
      "--------------------\n",
      "Tensor out = mean(z): 10.0\n",
      "Gradient function for out: <MeanBackward0 object at 0x306abbe50>\n",
      "--------------------\n",
      "--- Computing Gradients ---\n",
      "Gradient of out with respect to x (x.grad): 7.0\n",
      "Gradient of out with respect to y (y.grad): 2.0\n",
      "--------------------\n",
      "--- Non-scalar Backward Example ---\n",
      "Tensor a: tensor([1., 2., 3.], requires_grad=True)\n",
      "Tensor b = a * 2: tensor([2., 4., 6.], grad_fn=<MulBackward0>)\n",
      "Gradient of sum(b) with respect to a (a.grad): tensor([2., 2., 2.])\n",
      "--------------------\n",
      "--- Disabling Gradient Tracking ---\n",
      "Tensor n (created inside no_grad): 50.0\n",
      "Does n require grad? False\n",
      "Tensor p (original): 50.0\n",
      "Does p require grad? True\n",
      "Tensor q (detached from p): 50.0\n",
      "Does q require grad? False\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# --- 1. Creating Tensors with requires_grad=True ---\n",
    "# Tensors that require gradients will track operations performed on them.\n",
    "# This is typically set for model parameters (weights and biases).\n",
    "print(\"--- Creating Tensors ---\")\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "print(f\"Tensor x: {x}\")\n",
    "print(f\"Tensor y: {y}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# --- 2. Performing Operations and Building the Computational Graph ---\n",
    "# PyTorch automatically builds a dynamic computational graph as you perform operations\n",
    "# on tensors that require gradients.\n",
    "print(\"--- Performing Operations ---\")\n",
    "z = x * y + x**2\n",
    "print(f\"Tensor z = x * y + x^2: {z}\")\n",
    "# Notice that z has a grad_fn, indicating it's part of the graph\n",
    "print(f\"Gradient function for z: {z.grad_fn}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Let's add another operation\n",
    "out = z.mean()\n",
    "print(f\"Tensor out = mean(z): {out}\")\n",
    "print(f\"Gradient function for out: {out.grad_fn}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# --- 3. Computing Gradients with .backward() ---\n",
    "# When you call .backward() on a scalar tensor (like our 'out'),\n",
    "# PyTorch computes the gradients of that tensor with respect to all\n",
    "# tensors that have requires_grad=True and are part of the graph.\n",
    "# The gradients are accumulated in the .grad attribute of these tensors.\n",
    "print(\"--- Computing Gradients ---\")\n",
    "out.backward()\n",
    "\n",
    "# --- 4. Accessing the Computed Gradients ---\n",
    "# The gradients are now available in the .grad attribute.\n",
    "# Let's manually verify the gradients:\n",
    "# z = x*y + x^2\n",
    "# out = mean(z) (since z is a scalar here, mean(z) = z)\n",
    "# So, out = x*y + x^2\n",
    "# d(out)/dx = y + 2*x\n",
    "# d(out)/dy = x\n",
    "# At x=2.0, y=3.0:\n",
    "# d(out)/dx = 3.0 + 2*2.0 = 3.0 + 4.0 = 7.0\n",
    "# d(out)/dy = 2.0\n",
    "\n",
    "print(f\"Gradient of out with respect to x (x.grad): {x.grad}\")\n",
    "print(f\"Gradient of out with respect to y (y.grad): {y.grad}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# --- Example with a non-scalar tensor and .backward(gradient) ---\n",
    "print(\"--- Non-scalar Backward Example ---\")\n",
    "a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "b = a * 2\n",
    "print(f\"Tensor a: {a}\")\n",
    "print(f\"Tensor b = a * 2: {b}\")\n",
    "\n",
    "# b is not a scalar. To compute gradients, we need to pass a gradient argument\n",
    "# to .backward(). This argument is a tensor of the same shape as 'b' and\n",
    "# represents the gradient of some scalar loss with respect to 'b'.\n",
    "# A common case is the gradient of the sum of 'b' with respect to 'b',\n",
    "# which is a tensor of ones.\n",
    "gradient_of_sum = torch.tensor([1.0, 1.0, 1.0])\n",
    "b.backward(gradient=gradient_of_sum)\n",
    "\n",
    "# d(sum(b))/da_i = d(a_i * 2 + sum(a_j * 2 for j!=i))/da_i = 2\n",
    "print(f\"Gradient of sum(b) with respect to a (a.grad): {a.grad}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# --- 5. Disabling Gradient Tracking ---\n",
    "# You might want to disable gradient tracking during inference or when\n",
    "# updating model weights to save memory and computation.\n",
    "\n",
    "print(\"--- Disabling Gradient Tracking ---\")\n",
    "m = torch.tensor(5.0, requires_grad=True)\n",
    "\n",
    "# Method 1: Using torch.no_grad() context manager\n",
    "with torch.no_grad():\n",
    "    n = m * 10\n",
    "print(f\"Tensor n (created inside no_grad): {n}\")\n",
    "print(f\"Does n require grad? {n.requires_grad}\")\n",
    "\n",
    "# Method 2: Using .detach()\n",
    "p = m * 10\n",
    "q = p.detach()\n",
    "print(f\"Tensor p (original): {p}\")\n",
    "print(f\"Does p require grad? {p.requires_grad}\")\n",
    "print(f\"Tensor q (detached from p): {q}\")\n",
    "print(f\"Does q require grad? {q.requires_grad}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Note: Gradients are accumulated. If you run backward multiple times\n",
    "# on the same tensors without zeroing the gradients, they will add up.\n",
    "# In training loops, you typically zero gradients before each backward pass\n",
    "# using optimizer.zero_grad() or tensor.grad.zero_().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f58c3-3214-4842-b505-02abdc4068f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
