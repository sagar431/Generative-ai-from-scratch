# Fundamentals

This directory contains implementations of fundamental concepts necessary for building Large Language Models.

## Directory Structure

- `tokenization/`: Implementation of different tokenization techniques
  - BPE (Byte Pair Encoding)
  - WordPiece
  - SentencePiece
  
- `embeddings/`: Word and sentence embedding implementations
  - Word2Vec
  - Positional Embeddings
  - Token Embeddings
  
- `attention/`: Basic attention mechanism implementations
  - Self-attention
  - Scaled Dot-Product Attention
  - Basic attention patterns

Each subdirectory contains its own README with specific implementation details and examples. 